{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a quick tutorial on Tensorflow based on Stanford CS 20SI\n",
    "\n",
    "All images are belonged to CS 20SI authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 1: Basic notation and stuff\n",
    "\n",
    "<img src=\"graph_stuff.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Tensorflow is not like numpy (although both gives us tools working with matrix, vector, etc...), thus the way to buidling a tensorflow application is different (a little bit) <br>  _\n",
    "\n",
    "When discussing deep learning, what comes up into our mind is the backpropagation algorithm, we let the \"flow\" flow toward and backward our deep learning model. The \"flow\" goes through each layer, which we often imagine (or at least visualize) is a bunch of circle (neurons, nodes, etc...) connected to each other in the particular structure, layer by layer. That can be called as computational graph. We can see that illustration in figure above **each node is much more simpler than the node we known in neural network, but that's ok)** <br>\n",
    "\n",
    "In tensorflow, we _**must define a computational graph, however, it is not simply the same as the deep neural networks model. As we shall see, the graph in Tensorflow is based on that but a little bit different. For example, the optimization step (learning process) in our model is also included in our graph (and more...)**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Import tensorflow\n",
    "import tensorflow as tf # many people do this, good for copy and paste code >:) \n",
    "'''What is a tensor? in the name tensorflow\n",
    "   In short: it is a matrix, but it is a little bit trickier to get it\n",
    "'''\n",
    "\n",
    "#Example number 1:\n",
    "a = tf.add(3,5)\n",
    "print a #Where is 8???\n",
    "\n",
    "\n",
    "#But first let look at how tensorflow (\"board\" actually) represents the graph\n",
    "#We will come to this later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"TensorBoard_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:Where do x and y come from??? It must be 3 and 5??? <br>\n",
    "\n",
    "A: Tensorflow automatically do that (so we don't need to care about it, afterall this is a tool for us)\n",
    "\n",
    "Q: How to get the value of a??\n",
    "\n",
    "A: Use \"Session\" in tensorflow, basically, we let the graph flow now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print sess.run(a)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#But oftenfly, ppl do this:\n",
    "with tf.Session() as sess:\n",
    "    print sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7776\n",
      "Tensor(\"Add_5:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#More complex example:\n",
    "x = 2\n",
    "y = 3\n",
    "op1 = tf.add(x, y)\n",
    "op2 = tf.multiply(x, y)\n",
    "op3 = tf.pow(op2, op1)\n",
    "with tf.Session() as sess:\n",
    "    op3 = sess.run(op3)\n",
    "    print op3 #we got the value of op3\n",
    "    print op1 #we got bullshit again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"TensorBoard_2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7776\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "op1 = tf.add(x, y)\n",
    "op2 = tf.multiply(x, y)\n",
    "op3 = tf.pow(op2, op1)\n",
    "with tf.Session() as sess:\n",
    "    [op3, op1] = sess.run([op3,op1])\n",
    "    print op3 #we got the value of op3\n",
    "    print op1 #we got good stuff again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 note: if there is a node op4 = op1+op2, we run sess.run(op3), op4 will not be computed (save time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have discussed quite about graph, but we have not seen any \"graph\" in our code.<br>\n",
    "**Actually, we run session, which runs the default graph. As you may know, we can work on GPU with tensorflow, and if we smartly define our model such that it composed of several separated graph, then each graph can be computed using separated GPU (cool right?). We shall see in other tutorials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
