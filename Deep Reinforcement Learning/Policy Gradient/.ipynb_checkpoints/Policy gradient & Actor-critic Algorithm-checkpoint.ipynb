{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy gradient and actor critic algorithms\n",
    "\n",
    "-- This is based on UCB Deep RL course --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import logz\n",
    "import scipy.signal\n",
    "import os\n",
    "import time\n",
    "import inspect\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## Visualization purpose\n",
    "import helper\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-01-06 02:18:32,082] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of step:  12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<script language=\"javascript\">\n",
       "  /* Define the Animation class */\n",
       "  function Animation(frames, img_id, slider_id, interval, loop_select_id){\n",
       "    this.img_id = img_id;\n",
       "    this.slider_id = slider_id;\n",
       "    this.loop_select_id = loop_select_id;\n",
       "    this.interval = interval;\n",
       "    this.current_frame = 0;\n",
       "    this.direction = 0;\n",
       "    this.timer = null;\n",
       "    this.frames = new Array(frames.length);\n",
       "\n",
       "    for (var i=0; i<frames.length; i++)\n",
       "    {\n",
       "     this.frames[i] = new Image();\n",
       "     this.frames[i].src = frames[i];\n",
       "    }\n",
       "    document.getElementById(this.slider_id).max = this.frames.length - 1;\n",
       "    this.set_frame(this.current_frame);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.get_loop_state = function(){\n",
       "    var button_group = document[this.loop_select_id].state;\n",
       "    for (var i = 0; i < button_group.length; i++) {\n",
       "        var button = button_group[i];\n",
       "        if (button.checked) {\n",
       "            return button.value;\n",
       "        }\n",
       "    }\n",
       "    return undefined;\n",
       "  }\n",
       "\n",
       "  Animation.prototype.set_frame = function(frame){\n",
       "    this.current_frame = frame;\n",
       "    document.getElementById(this.img_id).src = this.frames[this.current_frame].src;\n",
       "    document.getElementById(this.slider_id).value = this.current_frame;\n",
       "  }\n",
       "\n",
       "  Animation.prototype.next_frame = function()\n",
       "  {\n",
       "    this.set_frame(Math.min(this.frames.length - 1, this.current_frame + 1));\n",
       "  }\n",
       "\n",
       "  Animation.prototype.previous_frame = function()\n",
       "  {\n",
       "    this.set_frame(Math.max(0, this.current_frame - 1));\n",
       "  }\n",
       "\n",
       "  Animation.prototype.first_frame = function()\n",
       "  {\n",
       "    this.set_frame(0);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.last_frame = function()\n",
       "  {\n",
       "    this.set_frame(this.frames.length - 1);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.slower = function()\n",
       "  {\n",
       "    this.interval /= 0.7;\n",
       "    if(this.direction > 0){this.play_animation();}\n",
       "    else if(this.direction < 0){this.reverse_animation();}\n",
       "  }\n",
       "\n",
       "  Animation.prototype.faster = function()\n",
       "  {\n",
       "    this.interval *= 0.7;\n",
       "    if(this.direction > 0){this.play_animation();}\n",
       "    else if(this.direction < 0){this.reverse_animation();}\n",
       "  }\n",
       "\n",
       "  Animation.prototype.anim_step_forward = function()\n",
       "  {\n",
       "    this.current_frame += 1;\n",
       "    if(this.current_frame < this.frames.length){\n",
       "      this.set_frame(this.current_frame);\n",
       "    }else{\n",
       "      var loop_state = this.get_loop_state();\n",
       "      if(loop_state == \"loop\"){\n",
       "        this.first_frame();\n",
       "      }else if(loop_state == \"reflect\"){\n",
       "        this.last_frame();\n",
       "        this.reverse_animation();\n",
       "      }else{\n",
       "        this.pause_animation();\n",
       "        this.last_frame();\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.anim_step_reverse = function()\n",
       "  {\n",
       "    this.current_frame -= 1;\n",
       "    if(this.current_frame >= 0){\n",
       "      this.set_frame(this.current_frame);\n",
       "    }else{\n",
       "      var loop_state = this.get_loop_state();\n",
       "      if(loop_state == \"loop\"){\n",
       "        this.last_frame();\n",
       "      }else if(loop_state == \"reflect\"){\n",
       "        this.first_frame();\n",
       "        this.play_animation();\n",
       "      }else{\n",
       "        this.pause_animation();\n",
       "        this.first_frame();\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.pause_animation = function()\n",
       "  {\n",
       "    this.direction = 0;\n",
       "    if (this.timer){\n",
       "      clearInterval(this.timer);\n",
       "      this.timer = null;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.play_animation = function()\n",
       "  {\n",
       "    this.pause_animation();\n",
       "    this.direction = 1;\n",
       "    var t = this;\n",
       "    if (!this.timer) this.timer = setInterval(function(){t.anim_step_forward();}, this.interval);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.reverse_animation = function()\n",
       "  {\n",
       "    this.pause_animation();\n",
       "    this.direction = -1;\n",
       "    var t = this;\n",
       "    if (!this.timer) this.timer = setInterval(function(){t.anim_step_reverse();}, this.interval);\n",
       "  }\n",
       "</script>\n",
       "\n",
       "<div class=\"animation\" align=\"center\">\n",
       "    <img id=\"_anim_imgLQFDWMXSZERPYXHQ\">\n",
       "    <br>\n",
       "    <input id=\"_anim_sliderLQFDWMXSZERPYXHQ\" type=\"range\" style=\"width:350px\" name=\"points\" min=\"0\" max=\"1\" step=\"1\" value=\"0\" onchange=\"animLQFDWMXSZERPYXHQ.set_frame(parseInt(this.value));\"></input>\n",
       "    <br>\n",
       "    <button onclick=\"animLQFDWMXSZERPYXHQ.slower()\">&#8211;</button>\n",
       "    <button onclick=\"animLQFDWMXSZERPYXHQ.first_frame()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAgaeZk4EQAAASlJREFUKM/dkj9LQnEUhp9zr3bpj1uBcKGiJWxzLWivKAIRjIhcCqcgqJbKRagPICiVSVEuNTu0tLYGUg4tkRGUdxLJ0u79Ndxr5FfwTO/L+xzO4XCgO+v2T70AFU+/A/Dhmlzg6Pr0DKAMwOH4zQxAAbAkv2xNeF2RoQUVc1ytgttXUbWVdN1dOPE8pz4j4APQsdFtKA0WY6vpKjqvVciHnvZTS6Ja4HgggJLs7MHxl9nCh8NYcO+iGG0agiaC4h9oa6Vsw2yiK+QHSZT934YoEQABNBcTNDszsrhm1m1B+bFS86PT6QFppx6oeSaeOwlMXRp1h4aK13Y2kuHhUo9ykPboPvFjeEvsrhTMt3ylHyB0r8KZyYdCrbfj4OveoHMANjuyx+76rV+/blxKMZUnLgAAAABJRU5ErkJggg==\"></button>\n",
       "    <button onclick=\"animLQFDWMXSZERPYXHQ.previous_frame()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAgyTCyQ6wAAANRJREFUKM9jYBjO4AiUfgzFGGAp4+yayUvX6jMwMDCsYmBgOCS4OAOrSYmMgcc8/pd5Q3irC+Neh/1AlmeBMVgZmP8yMLD8/c/cqv9r90whzv/MX7Eq/MfAwMDIwCuZdfSV8U8WDgZGRmYGrAoZGRgY/jO8b3sj/J2F6T8j4z80pzEhmIwMjAxsSbqqlkeZGP//Z8SlkJnhPwMjwx/Guoe1NhmRwk+YGH5jV8jOwMPHzcDBysAwh8FrxQwtPU99HrwBXsnAwMDAsJiBgYGBoZ1xmKYqALHhMpn1o7igAAAAAElFTkSuQmCC\"></button>\n",
       "    <button onclick=\"animLQFDWMXSZERPYXHQ.reverse_animation()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAgmVvZElgAAAVFJREFUKM+t0k8ow3EYx/H3s/2aLDUSZctFkgsHEi1XLi5ukpPSWsuJklwclsPSsDKFi7MSJ0I5qF2GHO2m0FY7+BdNv7Y9DpuxDSt5vsfvq+fT9/k+8D8VBxIAWH6H0ead4Qb5BRwCENoceZi5Stl/6BgCBmtWhjzxg4mUQ02rAhil7JgB9tze7aTLxFAKsUUd14B9ZzCyFUk401gQyQJaDNcBHwv7t7ETd0ZVQFEEzcNCdE/1wtj15imGWlEB8qkf2QaAWjbG/bPSamIDyX65/iwDIFx7tWjUvWCoSo5oGbYATN7PORt7W9IZEQXJH8ohuN7C0VVX91KNqYhq4a1lEGJI0j892tazXCWQRUpwAbYDcHczPxXuajq3mbnhfANz5eOJxsuNvs7+jud0UcuyL3QAkuEMx4rnIvBYq1JhEwPAUb3fG7x8tVdc292/7Po7f2VqA+Yz7ZwAAAAASUVORK5CYII=\"></button>\n",
       "    <button onclick=\"animLQFDWMXSZERPYXHQ.pause_animation()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAkR91DQ2AAAAKtJREFUKM9jYCANTEVib2K4jcRbzQihGWEC00JuNjN8Z2Q0Zo3VYWA4lL005venH9+c3ZK5IfIsMIXMBtc12Bj+MMgxMDAwMPzWe2TBzPCf4SLcZCYY4/9/RgZGBiaYFf8gljFhKiQERhUOeoX/Gf8y/GX4y/APmlj+Mfxj+MfwH64Qnnq0zr9fyfLrPzP3eQYGBobvk5x4GX4xMIij23gdib0cRWYHiVmAAQDK5ircshCbHQAAAABJRU5ErkJggg==\"></button>\n",
       "    <button onclick=\"animLQFDWMXSZERPYXHQ.play_animation()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAkEmo00MwAAAS9JREFUKM+tkj1IQmEUhp9j94LQj0FD4RRBLdLQ3ftb26PRcCiQIIiIDFwKC0OhaAiam5wVDBpqCKohQojMLYzaAiUatOtpuQrKVQl64fu+4Xt4OLwc+Fs+nNM16jsPAWS6gZXggoZfXmfhog3hcZ6aTXF87Sp68OmH4/YggAo8bmfyyeh6Z1AAKPVldyO1+Iz2uILq3AriJSe3l+H7aj+cuRnrTsVDxSxay+VYbMDnCtZxxQOU9G4nlU9E1HQBxRkCQMRGRnIbpxMARkvxCIoAorYMMrq0mJ0qu4COUW3xyVDqJC4P+86P0ewDQbQqgevhlc2C8ETApXAEFLzvwa3EXG9BoIE1GQUbv1h7k4fTXxBu6cKgUbX5M3ZzNC+a7rQ936HV56SlRpcle+Mf8wvgJ16zo/4BtQAAAABJRU5ErkJggg==\"></button>\n",
       "    <button onclick=\"animLQFDWMXSZERPYXHQ.next_frame()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAkd/uac8wAAAMhJREFUKM9jYBie4DEUQ8B+fEq3+3UrMzAwMFxjYGBgYJizYubaOUxYFUaXh/6vWfRfEMIL/+//P5gZJoei4/f/7wxnY1PeNUXdE2RgYGZgYoCrY2BBVsjKwMDAwvCS4f3SG/dXxm5gYESSQ1HIwvCPgZmB8f8Pxv+Kxxb/YfiPJIdi9T8GJgaG/38ZFd4Fx0xUYsZt4h8GBgb2D2bLy7KnMTAwMEIxFoVCXIYr1IoDnkF4XAysqNIwUMDAwMDAsADKS2NkGL4AAIARMlfNIfZMAAAAAElFTkSuQmCC\"></button>\n",
       "    <button onclick=\"animLQFDWMXSZERPYXHQ.last_frame()\"><img class=\"anim_icon\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAQAAAAngNWGAAAAAXNSR0IArs4c6QAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3QURCAknOOpFQQAAAS9JREFUKM/dkrEvQ3EQxz/33mtoQxiYpANbLU26NAabSCcSUouGBVNDjYQaOiDpIEiKjURIw2Kx04hEYmkHEpGoJpSISaXq9Wd4P03/ht5y98197/u9XA4aK4rAWw3lgWddZ3S+/G9mEovtAB8AHE4pgTQAx8PbJweRmsq6GimmNpxaNYXVzMNNCI6A2figimwCGACK786zuWgh3qcsKf/w0pM4X0m/doNVFVzVGlEQsdRj193VxEWpH0RsdRu+zi3tVMqCAsDShoiYqiSV4OouVDFEqS9Pbiyg7vV62lpQ2BJ4Gg0meg0MbNpkYG/e+540NNFyrE1a8qHk5BaAjfnrzUaHfAWImVrLIXbgnx4/9X06s35cweWsVACa3a24PVp0X+rPv1aHFnSONdiL8Qci0lzwpOM5sQAAAABJRU5ErkJggg==\"></button>\n",
       "    <button onclick=\"animLQFDWMXSZERPYXHQ.faster()\">+</button>\n",
       "  <form action=\"#n\" name=\"_anim_loop_selectLQFDWMXSZERPYXHQ\" class=\"anim_control\">\n",
       "    <input type=\"radio\" name=\"state\" value=\"once\" > Once </input>\n",
       "    <input type=\"radio\" name=\"state\" value=\"loop\" checked> Loop </input>\n",
       "    <input type=\"radio\" name=\"state\" value=\"reflect\" > Reflect </input>\n",
       "  </form>\n",
       "</div>\n",
       "\n",
       "\n",
       "<script language=\"javascript\">\n",
       "  /* Instantiate the Animation class. */\n",
       "  /* The IDs given should match those used in the template above. */\n",
       "  (function() {\n",
       "    var img_id = \"_anim_imgLQFDWMXSZERPYXHQ\";\n",
       "    var slider_id = \"_anim_sliderLQFDWMXSZERPYXHQ\";\n",
       "    var loop_select_id = \"_anim_loop_selectLQFDWMXSZERPYXHQ\";\n",
       "    var frames = new Array(0);\n",
       "    \n",
       "  frames[0] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABLpJREFUeJzt3NFJw1AYgFGvdInO4Rqdo85k5nAN53CM2zdRFLFaEj5zDgRCIOF/CR83CRlzznkHADH3Ww8AAL8hYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASYetB4C9eVkevzz+cH5aeRJoswIDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAGDGxlj/Gj76/nfXQP2RMAASDpsPQDs1fPr+W3/dFw2nASaBAxW9j5cH4+JGFzDI0QAkgQMgCQBg5Wdjsund17egcH1xpxzbj0E/Adrft7utgUrMACiBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACS/I0ebsTfMWBdVmAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJF0ACIUeFK6lLygAAAAASUVORK5CYII=\"\n",
       "  frames[1] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABLpJREFUeJzt3NFJw1AYgFGvdInO4Rqdo85k5nAN53CM2zdRFLFaEj5zDgRCIOF/CR83CRlzznkHADH3Ww8AAL8hYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASYetB4C9eVkevzz+cH5aeRJoswIDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAGDGxlj/Gj76/nfXQP2RMAASDpsPQDs1fPr+W3/dFw2nASaBAxW9j5cH4+JGFzDI0QAkgQMgCQBg5Wdjsund17egcH1xpxzbj0E/Adrft7utgUrMACiBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACS/I0ebsTfMWBdVmAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJF0ACIUeFK6lLygAAAAASUVORK5CYII=\"\n",
       "  frames[2] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABMFJREFUeJzt3NFpwlAAhlFTXMI52jGcQ2dq5nCNzuEY1+eWUqotiZ+eA3kREv6X8HEhOI0xxgYAYl7WHgAAtxAwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDICk7doD4Nl8zMdvf389vC+8BNqcwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwOCfTNP0q+uv9//0DHgmAgZAkoDBSk7nw+Z0Pqw9A7IEDBb2NVwiBrcRMLgDIgbXEzC4A/vdvPYEyBEwWNh+N38K1n43b96OAgbXmsYYY+0R8AiW/LzdawtOYABECRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkbdceAI/Cv2PAspzAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEi6AGx0JK6D10LbAAAAAElFTkSuQmCC\"\n",
       "  frames[3] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABMBJREFUeJzt3MFtgmAYgGFpXMI52jGcg67hGnUOx2jncIy/B09NPGhrIG99noQDJJDvQt78QJjGGGMDADEvaw8AAL8hYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASdu1B4Bn83V8v3r8df5YeBJoswIDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAGDB5im6ebtr9cALgQMgCQBg5WczvPmdJ7XHgOypjHGWHsIqLvn0d7h8Hnl2NvN57tl4cIKDIAkAQMgScBgYfvdcbPfHX/sA/fzDgweYMnP292ycGEFBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkDSdu0B4D/wdwxYnhUYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEnfqHUkcel4geoAAAAASUVORK5CYII=\"\n",
       "  frames[4] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABMBJREFUeJzt3NFJw1AYgFEjXaJzuEbnqDOZOVzDORzj+iZKpVgtuX72HAiUCyn/S/i4SZtljDHuACDmfvYAAPATAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkLSbPQDcmpf18WTt4fg0YRJoswMDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAz+gK/+GwacJ2AAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGBwJcuyfOv47fnnvgNuiYABkLSbPQDcqufX4/vnw36dOAk0CRhs7GO4Pq+JGFzCLUQAkgQMgCQBg40d9uvJMy/PwOByyxhjzB4C/oMtf97usgU7MACiBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSvI0ersTbMWBbdmAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJL0BxSEf4hhtiScAAAAASUVORK5CYII=\"\n",
       "  frames[5] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABMBJREFUeJzt3NFJw1AYgFEjXaJzuEbnaGcyc7hG53CM65soBbFacv3sORAIgYT/JXzcJGQZY4wHAIh5nD0AAPyEgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJO1mDwD35ryeLo49HZ8nTAJtVmAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBn/AeT3NHgFyBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAGDG1mW5Vvbb8//6hpwTwQMgKTd7AHgXr28Ht/3D/t14iTQJGCwsY/h+nxMxOAaHiECkCRgACQJGGzssF8v3nl5BwbXW8YYY/YQ8B9s+Xm72xaswACIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABI8jd6uBF/x4BtWYEBkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkPQGqe0f4uB06FgAAAAASUVORK5CYII=\"\n",
       "  frames[6] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABMFJREFUeJzt3d1JxEAYQFEj24R12IZ17NZk6rCNrcMyxjcRFX9DxuueA4EksOF7CZcJS7KMMcYVAMRczx4AAH5CwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkg6zB4BLc15Pb87dHu8nTAJtVmAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgMEfcF5Ps0eAHAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAGDjSzL8qXtt7//6BpwSQQMgKTD7AHgUj08Hp/3727WiZNAkxUYTPAyXu8dA58TMNiZWME2BAx25nEhbEPAYILXERM1+L5ljDFmDwH/wZ5/b3fbghUYAFECBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEk+pwIb8XYM2JcVGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJT3VfIUd6RLh1AAAAAElFTkSuQmCC\"\n",
       "  frames[7] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABMVJREFUeJzt3dFpwmAYQNGmuETncI3OoTPpHF3DOTrG71vpQx9stfm9eg4EJBD4XuTyhZAsY4zxAgAxr7MHAIC/EDAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgKTN7AHgmZyO+x/Pb3eHlSeBPhsYAEkCBiuyacHtCBgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGd+B03M8eAXIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAYOVbXeH2SPAQxAwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAYMbWZbl4uM/rodnI2AAJG1mDwDP6uNz9/X7/e04cRJosoHBHfgeM+AyAgYTCBZcT8BgArcM4XoCBndA0OD3ljHGmD0EPII1H2/3twUbGABRAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJPqcCN+LtGLAuGxgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASWdkViCuHGdlBgAAAABJRU5ErkJggg==\"\n",
       "  frames[8] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABNlJREFUeJzt3dFJw1AYgFEjXcI5uoZzNDM1c7hG53CM+CYiRaqW3H7tORBoAoH/JXzcEG6ndV3XJwCIeR49AAD8hYABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACTtRg8Aj+S0zGev7w/HjSeBPiswAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAYMN2TIKrkfAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAGDG3Ba5tEjQI6AAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAwcb2h+PoEeAuCBgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgMcG5D39MyD5gEugQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjC4ommaLj7OOS3zv+6HRyJgACTtRg8Aj+zt/fD5+/VlGTgJ9FiBwSBf43XuHPiZgMENETG4nIDBDfEaES4nYDDI91iJF/zOtK7rOnoIuBdbft7u0eXRWYEBkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkOTvVOCK7I4B27ECAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyDpA8zQKHlArD9KAAAAAElFTkSuQmCC\"\n",
       "  frames[9] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABN9JREFUeJzt3dtNAlEUQFHG0IR1aBnWATVBHZahdVjG+O0rDkK4s2WthA9IIOeH7Fwyw5nmeZ43ABBzN3oAAPgLAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASNqOHgBuyetx/+W1h91hwCTQ5wQGQJKAAZAkYAAkCRgASQIGQJKAAZAkYDDYd5fWA78TMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnA4IqsToHLETAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwGAF7ASD0wkYAEkCBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGBwZXaCwWUIGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgsBJ2gsFpBAwGcDMznE/AAEgSMACSBAyAJAEDIEnAAEgSMACSBAxWxL1gsJyAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGg1ipAucRMACSBAyAJAEDIEnAAEgSMACSBAwubJqmxY9z3//TZ8AtEDAAkrajB4Bb9/y2+/D85bDZPO6Pg6aBDicwGOhzvIDlBAxWRtRgGQGDlXm69/MhLCFgMJBYwd9N8zzPo4eA/+Tal7b7CnOrnMAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASLJOBS7MP2PAdTiBAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZAkYAAkCRgASQIGQJKAAZD0Dpz9KhoKneDVAAAAAElFTkSuQmCC\"\n",
       "  frames[10] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABO1JREFUeJzt3cFNAlEUQFHG0IR1aBnWATVJHbZhHZYxrhUScQT+XDwnYQEL8jbk5pOfN9M8z/MGAGIeRg8AAEsIGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZA0nb0APBfvB/2R5897V4HTAL3wQkMBjoVNeA8AgZAkoABkCRgACQJGABJAgY34sYhXJaAAZAkYAAkCRgASQIGQJKAAZAkYDCYdVKwjIABkCRgACQJGABJAgZAkoABkCRgcEP2IcLlCBgASQIGQJKAAZAkYAAkCRisgHVS8HsCBkCSgAGQJGAAJAkYAEkCBkCSgMGNWScFlyFgACQJGABJAgZAkoABkCRgMMCpixzWScHvCBgASQIGQJKAAZAkYAAkCRgASQIGK+ImIpxPwABIEjAAkgQMgCQBAyBJwGAQzwWDvxEwAJIEDIAkAQMgScAASBIwWBnbOOA8AgZAkoABkCRgACQJGABJAgZAkoDBQNZJwXICBkCSgAGQJGAAJAkYAEkCBlcwTdPZr1PeD/s/fwfcOwEDIGk7egBgs3n72H15//J4GDQJdDiBwQp9DxpwTMBgMLGCZQQMBvN3ISwjYDDY8/44YKIGP5vmeZ5HDwH35tZX2/2M+Y+cwABIEjAAkgQMgCQBAyBJwABIEjAAkgQMgCQBAyBJwABI8jgVuAKbMeD6nMAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASBIwAJIEDIAkAQMgScAASPoEFusxf2SMZ2gAAAAASUVORK5CYII=\"\n",
       "  frames[11] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABQBJREFUeJzt3NFN21AYgFG7YonO0Y7ROWAmMkfHgDk6hvuGKighGOPrL5wjWUoeEt0X65Ov/XtelmWZACDm2+gFAMAaAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkHQzegHw1Tye7p4+/7i9H7gSaBMw2MG/0QK2YQsRgCQBgx3YKoTtCRgASQIGQJKAAZAkYDCQpxNhPQEDIEnAAEgSMACSBAx2YhYMtiVgACQJGABJAgZAkoDBYGbBYB0BAyBJwABIEjAAkgQMdmQWDLYjYAAkCRgASQIGQJKAwQGYBYP3EzAAkgQMgCQBAyBJwGBnZsFgGwIGQJKAAZAkYAAkCRgM8L/7YGbB4H0EDIAkAQMgScAASBIwOBD3weByAgZAkoABkCRgACQJGAzinYjwMQIGQJKAAZAkYAAkCRgcjFkwuIyAAZAkYAAkCRgASQIGA5kFg/UEDIAkAQMgScAASBIwOCCzYPA2AQMgScAASBIwAJIEDAYzCwbrCBgASQIGQJKAAZAkYHBQZsHgPAEDIEnA4BPN83zR8dHfn/sPuFYCBkCSgMEB/Lw7TdM0Tb//3D4dwHkCBgfxPFoiBucJGABJAgZAkoDBQfz6fnrx/eHeNiK8Zl6WZRm9CLhWez7e7lTmq3EFBkCSgAGQJGAAJAkYAEkCBkCSgAGQJGAAJAkYAEkCBkDSzegFwDXzdgz4PK7AAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEgSMACSBAyAJAEDIEnAAEj6C7nnPEq02BoiAAAAAElFTkSuQmCC\"\n",
       "  frames[12] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAEgCAYAAADVKCZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABSBJREFUeJzt3cFNG1EARdFMRBOpIymDOqAN2oA6UgapI2UMiywSxYbYg5n/r3OOxMKWsP4GXc3wbC/ruq6fACDm8+gDAMAWAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACTdjD4AXLsfT/dHn/9697jzSeC6uAKDDyZU8DEEDIAkAQMgScBgkNf+NwacRsAASBIwAJIEDHZgiQiXJ2AAJAkYAEkCBgNZIsJ2AgZAkoABkCRgsBNLRLgsAQMgScAASBIwGMwSEbYRMACSBAyAJAGDHVkiwuUIGABJAgZAkoDBBCwR4XwCBkCSgAGQJGCwM0tEuAwBAyBJwABIEjAY4NhtREtEOI+AAZAkYAAkCRhMxG1EOJ2AAZAkYAAkCRgM4g3N8D4CBkCSgAGQJGAwGUtEOI2AAZAkYAAkCRgASQIGA5nSw3YCBkCSgMGELBHh3wQMgCQBAyBJwABIEjAYzBIRthEwAJIEDCZliQhvEzAAkgQMgCQBAyBJwGAClohwPgEDIEnAYGKWiPA6AQMgScAASBIwAJIEDCZhiQjnETDYwbIsJ/2853ffeg24RgIGE/l2/3Tw3PPj3YCTwPxuRh8AOPT95+9o3X45jBrgCgym82e8jj0GfhEwCHh4eB59BJiOgEGA24hwSMBgMn/HSrzguGVd13X0IeDa7Tlv9yfN/8IVGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJvk4FduDTMeDyXIEBkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkCRgACQJGABJAgZAkoABkPQCuVZBeXw1kRQAAAAASUVORK5CYII=\"\n",
       "\n",
       "\n",
       "    /* set a timeout to make sure all the above elements are created before\n",
       "       the object is initialized. */\n",
       "    setTimeout(function() {\n",
       "        animLQFDWMXSZERPYXHQ = new Animation(frames, img_id, slider_id, 50, loop_select_id);\n",
       "    }, 0);\n",
       "  })()\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "cum_reward = 0\n",
    "frames = []\n",
    "for t in range(5000):\n",
    "    # Render into buffer. \n",
    "    frames.append(env.render(mode = 'rgb_array'))\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    #print 'Observation: ', observation\n",
    "    if done:\n",
    "        print 'Number of step: ', t\n",
    "        break\n",
    "env.render(close=True)\n",
    "helper.display_frames_as_gif(frames)  #<<< This one for Jupyter Notebook Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states: Box(4,)\n",
      "Number of available actions:  Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "state = env.observation_space\n",
    "print 'Number of states:', state\n",
    "print 'Number of available actions: ',env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(\n",
    "        input_placeholder, \n",
    "        output_size,\n",
    "        scope, \n",
    "        n_layers=2, \n",
    "        size=64, \n",
    "        activation=tf.tanh,\n",
    "        output_activation=None\n",
    "        ):\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        # YOUR_CODE_HERE\n",
    "        layers = [0]*n_layers \n",
    "        for i in range(n_layers):\n",
    "            if i == 0:\n",
    "                layers[i] = tf.layers.dense(inputs = input_placeholder, units=size, activation= activation)\n",
    "            else:\n",
    "                layers[i] = tf.layers.dense(inputs = layers[i-1], units = size, activation=activation)\n",
    "        output_layer = tf.layers.dense(inputs = layers[n_layers -1], units = output_size, activation= output_activation)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.12933688]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#Test if our mlp run as we want it\n",
    "x = tf.placeholder(tf.float32, [None, 1], name= \"pixels_input\")\n",
    "y =build_mlp(x,1,\"test_mlp0\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out = sess.run([y], feed_dict = {x: [[3]]})\n",
    "    print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pathlength(path):\n",
    "    return len(path[\"reward\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "REINFORCE algorithm\n",
    "\n",
    "<img src = \"REINFORCE.png\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation dimension:  4\n",
      "Action dimension:  2\n"
     ]
    }
   ],
   "source": [
    "ob_dim = env.observation_space.shape[0]\n",
    "ac_dim = env.action_space.n\n",
    "print 'Observation dimension: ',ob_dim\n",
    "print 'Action dimension: ', ac_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build a policy network\n",
    "input_state = tf.placeholder(tf.float32, [None, ob_dim], name = 'State_input')\n",
    "action_prob = build_mlp(input_state, ac_dim, \"policy_network0\") #policy network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to implement the above equation in Tensorflow (gradient)\n",
    "\n",
    "- Consider just 1 episode\n",
    "- In the feed_dict, we are going to input 3 things: state visited, action taken, reward received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use autodiff, we need to compute that loss function\n",
    "sampled_action = tf.squeeze(tf.multinomial(action_prob, 1), axis=[1])\n",
    "\n",
    "#\n",
    "sy_ac_na = tf.placeholder(tf.int32, [None], name = 'Action_taken')\n",
    "logprob_n = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=sy_ac_na, logits=action_prob) #action_prob requires input_state\n",
    "\n",
    "#Loss function\n",
    "learning_rate = 0.01\n",
    "sy_ad_fn = tf.placeholder(shape=[None], name=\"adv\", dtype=tf.float32) \n",
    "weighted_negative_likelihood = tf.multiply(logprob_n, sy_ad_fn) #note that in softmax_cross_entropy function, there is actually a minus sign\n",
    "loss = tf.reduce_mean(weighted_negative_likelihood)\n",
    "update_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Running 1 episode for illustration:\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #Run 1 episode:\n",
    "    obs, acs, rewards = [], [], []\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        #Push the state into one list\n",
    "        obs.append(s)\n",
    "        ac_taken = sess.run(sampled_action, feed_dict={input_state: [s]}) #Take the sampled action\n",
    "        acs.append(ac_taken)\n",
    "        s, reward, done,info = env.step(ac_taken[0]) #Basically this is what we need\n",
    "        rewards.append(reward)\n",
    "    #We need to modify our reward function \n",
    "    for i in range(2, len(rewards)+1):\n",
    "        rewards[-i] = rewards[-i] + rewards[-i +1]\n",
    "    #We now got 3 elements to optimize our loss function:\n",
    "    #Write whatever we need for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step # 0\n",
      "Loss value: 9.18979\n",
      "Total reward after 1 episode after fitting: 19.0\n",
      "----------------------------------------\n",
      "Step # 1\n",
      "Loss value: 17.6493\n",
      "Total reward after 1 episode after fitting: 41.0\n",
      "----------------------------------------\n",
      "Step # 2\n",
      "Loss value: 21.7148\n",
      "Total reward after 1 episode after fitting: 37.0\n",
      "----------------------------------------\n",
      "Step # 3\n",
      "Loss value: 23.2361\n",
      "Total reward after 1 episode after fitting: 94.0\n",
      "----------------------------------------\n",
      "Step # 4\n",
      "Loss value: 26.1698\n",
      "Total reward after 1 episode after fitting: 60.0\n",
      "----------------------------------------\n",
      "Step # 5\n",
      "Loss value: 29.8446\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 6\n",
      "Loss value: 42.3815\n",
      "Total reward after 1 episode after fitting: 192.0\n",
      "----------------------------------------\n",
      "Step # 7\n",
      "Loss value: 44.7873\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 8\n",
      "Loss value: 44.0516\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 9\n",
      "Loss value: 45.3158\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 10\n",
      "Loss value: 45.0171\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 11\n",
      "Loss value: 44.5098\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 12\n",
      "Loss value: 43.8055\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 13\n",
      "Loss value: 43.0805\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 14\n",
      "Loss value: 43.1304\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 15\n",
      "Loss value: 44.04\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 16\n",
      "Loss value: 45.2489\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 17\n",
      "Loss value: 47.1\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 18\n",
      "Loss value: 47.8352\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 19\n",
      "Loss value: 48.9417\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 20\n",
      "Loss value: 50.342\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 21\n",
      "Loss value: 51.0008\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 22\n",
      "Loss value: 51.2437\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 23\n",
      "Loss value: 51.6079\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 24\n",
      "Loss value: 52.0664\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 25\n",
      "Loss value: 52.0819\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 26\n",
      "Loss value: 51.1935\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 27\n",
      "Loss value: 49.0349\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 28\n",
      "Loss value: 47.3384\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 29\n",
      "Loss value: 45.2157\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 30\n",
      "Loss value: 43.1255\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 31\n",
      "Loss value: 41.1989\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 32\n",
      "Loss value: 39.6487\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 33\n",
      "Loss value: 38.2826\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 34\n",
      "Loss value: 37.6024\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 35\n",
      "Loss value: 36.963\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 36\n",
      "Loss value: 36.5619\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 37\n",
      "Loss value: 36.7652\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 38\n",
      "Loss value: 36.7708\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 39\n",
      "Loss value: 36.4764\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 40\n",
      "Loss value: 37.0301\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 41\n",
      "Loss value: 36.9397\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 42\n",
      "Loss value: 37.827\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 43\n",
      "Loss value: 38.0458\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 44\n",
      "Loss value: 38.2825\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 45\n",
      "Loss value: 37.8087\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 46\n",
      "Loss value: 37.1227\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 47\n",
      "Loss value: 36.376\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 48\n",
      "Loss value: 35.8227\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 49\n",
      "Loss value: 35.3556\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 50\n",
      "Loss value: 35.7063\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 51\n",
      "Loss value: 35.7494\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 52\n",
      "Loss value: 35.283\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 53\n",
      "Loss value: 35.0253\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 54\n",
      "Loss value: 34.6902\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 55\n",
      "Loss value: 34.3898\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 56\n",
      "Loss value: 34.6903\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 57\n",
      "Loss value: 34.2885\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 58\n",
      "Loss value: 34.2173\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 59\n",
      "Loss value: 34.3791\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 60\n",
      "Loss value: 34.1922\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 61\n",
      "Loss value: 34.7925\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 62\n",
      "Loss value: 35.0727\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 63\n",
      "Loss value: 35.2716\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 64\n",
      "Loss value: 35.6375\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 65\n",
      "Loss value: 34.887\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 66\n",
      "Loss value: 33.5796\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 67\n",
      "Loss value: 32.8499\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value: 31.6035\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 69\n",
      "Loss value: 31.2663\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 70\n",
      "Loss value: 31.9859\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 71\n",
      "Loss value: 32.6756\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 72\n",
      "Loss value: 33.0545\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 73\n",
      "Loss value: 33.9648\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 74\n",
      "Loss value: 34.3131\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 75\n",
      "Loss value: 34.6482\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 76\n",
      "Loss value: 34.7913\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 77\n",
      "Loss value: 35.3122\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 78\n",
      "Loss value: 35.894\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 79\n",
      "Loss value: 35.7926\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 80\n",
      "Loss value: 36.0704\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 81\n",
      "Loss value: 36.348\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 82\n",
      "Loss value: 35.6412\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 83\n",
      "Loss value: 34.527\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 84\n",
      "Loss value: 33.9186\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 85\n",
      "Loss value: 32.7334\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 86\n",
      "Loss value: 31.6628\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 87\n",
      "Loss value: 31.2032\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 88\n",
      "Loss value: 30.054\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 89\n",
      "Loss value: 29.0902\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 90\n",
      "Loss value: 28.1859\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 91\n",
      "Loss value: 27.4691\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 92\n",
      "Loss value: 26.4877\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 93\n",
      "Loss value: 25.9682\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 94\n",
      "Loss value: 25.0651\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 95\n",
      "Loss value: 24.6626\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 96\n",
      "Loss value: 24.1496\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 97\n",
      "Loss value: 24.1807\n",
      "Total reward after 1 episode after fitting: 200.0\n",
      "----------------------------------------\n",
      "Step # 98\n",
      "Loss value: 23.7914\n",
      "Total reward after 1 episode after fitting: 169.0\n",
      "----------------------------------------\n",
      "Step # 99\n",
      "Loss value: 20.7505\n",
      "Total reward after 1 episode after fitting: 151.0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Start a real training\n",
    "init = tf.global_variables_initializer() \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        print'Step #',i\n",
    "        paths = []\n",
    "        # ep_obs1, ep_acs1, ep_res1 = [], [], [] --Debugging \n",
    "        for iters in range(200): #Run 200 episodes to estimate the mean\n",
    "            #Run 1 episode:\n",
    "            obs, acs, rewards = [], [], []\n",
    "            s = env.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                #Push the state into one list\n",
    "                obs.append(s)\n",
    "                ac_taken = sess.run(sampled_action, feed_dict={input_state: [s]}) #Take the sampled action\n",
    "                acs.append(ac_taken[0])\n",
    "                s, reward, done,info = env.step(ac_taken[0]) #Basically this is what we need\n",
    "                rewards.append(reward)\n",
    "            #We need to modify our reward function \n",
    "            for i in range(2, len(rewards)+1):\n",
    "                rewards[-i] = rewards[-i] + rewards[-i +1]\n",
    "            #We now got 3 elements to optimize our loss function:\n",
    "            #ep_obs1.append(obs)  -- Debugging\n",
    "            #ep_acs1.append(acs)  -- Debugging\n",
    "            #ep_res1.append(rewards) -- Debugging\n",
    "            path = {\"observation\" : np.array(obs), \n",
    "                    \"reward\" : np.array(rewards), \n",
    "                    \"action\" : np.array(acs)}\n",
    "            paths.append(path)\n",
    "        #Train it!\n",
    "        ep_obs = np.concatenate([path[\"observation\"] for path in paths])\n",
    "        ep_acs = np.concatenate([path[\"action\"] for path in paths])\n",
    "        ep_res = np.concatenate([path[\"reward\"] for path in paths])\n",
    "        _, loss_value = sess.run([update_op, loss], feed_dict={input_state: ep_obs,\n",
    "                                                               sy_ac_na: ep_acs,sy_ad_fn: ep_res})\n",
    "        print 'Loss value:', loss_value\n",
    "        \n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        total_rw = 0\n",
    "        while not done:\n",
    "            ac = sess.run(sampled_action, feed_dict={input_state: [s]})\n",
    "            s, reward, done,info = env.step(ac[0])\n",
    "            total_rw += reward\n",
    "        print 'Total reward after 1 episode after fitting:', total_rw\n",
    "        print \"----------------------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Yahoo, just finished the REINFORCE algorithm for that (maximum reward achieved --200 in the case of cart pole, try other environments! (mountain car))\n",
    "- Lower the number of episodes (from 200 to 10) to see how it affects the learning process\n",
    "- Increase the learning rate for the same reason\n",
    "- Now we are going to implement Actor-critic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
